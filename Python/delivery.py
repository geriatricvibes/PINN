{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bfa9ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Data Science snippet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.spatial.distance import cdist\n",
    "import imageio\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib.collections import PatchCollection\n",
    "\n",
    "plt.style.use(\"seaborn-dark\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from rl.agents.q_agent import QAgent\n",
    "\n",
    "class Environment(object):\n",
    "    def __init__(self,n_stops = 8,max_box = 8,method = \"angle_diff\",**kwargs):\n",
    "\n",
    "        print(f\"Initialized environment with {n_stops} incident points\")\n",
    "        print(f\"Target metric for optimization is {method}\")\n",
    "\n",
    "        # Initialization\n",
    "        self.n_stops = n_stops\n",
    "        self.action_space = self.n_stops\n",
    "        self.observation_space = self.n_stops\n",
    "        self.stops = []\n",
    "        self.method = method\n",
    "\n",
    "        # Generate stops\n",
    "        self.slope_func([self.x,self.y])\n",
    "        self.slope_matrix([self.x,self.y])\n",
    "        self._generate_stops()\n",
    "        self._generate_q_values()\n",
    "        self.render()\n",
    "\n",
    "        # Initialize first point\n",
    "        self.reset()\n",
    "        \n",
    "    \n",
    "    def _generate_stops(self):\n",
    "        \n",
    "        # Generate geographical coordinates\n",
    "        xy = np.loadtxt('test.csv', delimiter=\",\")\n",
    "        self.x = xy[:,0]\n",
    "        self.y = xy[:,1]\n",
    "   \n",
    "    def slope_func(self,a, b):\n",
    "        if (a[1]-b[1]) ==0:\n",
    "            s = +100\n",
    "        elif (a[1]!=0) and (b[1]!=0):\n",
    "            s = +100\n",
    "        else: \n",
    "            s = (a[0]-b[0])/(a[1]-b[1])\n",
    "        return s\n",
    "\n",
    "    def slope_matrix(self,a,b):\n",
    "        mat = np.zeros((len(a), len(b)))\n",
    "        for i in range(len(a)):\n",
    "            for j in range(len(b)):\n",
    "                mat[i][j] = _slope_func(a[j], b[i]);\n",
    "        return mat\n",
    "\n",
    "    def _generate_q_values(self,box_size = 0.2):\n",
    "\n",
    "        # Generate actual Q Values corresponding to time elapsed between two points\n",
    "        if self.method in [\"angle_diff\"]:\n",
    "            xy = np.column_stack([self.x,self.y])\n",
    "            self.q_stops = slope_matrix(xy,xy)\n",
    "        else:\n",
    "            raise Exception(\"Method not recognized\")\n",
    "\n",
    "    \n",
    " \n",
    "\n",
    "    def render(self,return_img = False):\n",
    "        \n",
    "        fig = plt.figure(figsize=(7,7))\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.set_title(\"Delivery Stops\")\n",
    "\n",
    "        # Show stops\n",
    "        ax.scatter(self.x,self.y,c = \"red\",s = 50)\n",
    "\n",
    "        # Show START\n",
    "        if len(self.stops)>0:\n",
    "            xy = self._get_xy(initial = True)\n",
    "            xytext = xy[0]+0.1,xy[1]-0.05\n",
    "            ax.annotate(\"START\",xy=xy,xytext=xytext,weight = \"bold\")\n",
    "\n",
    "        # Show itinerary\n",
    "        if len(self.stops) > 1:\n",
    "            ax.plot(self.x[self.stops],self.y[self.stops],c = \"blue\",linewidth=1,linestyle=\"--\")\n",
    "            \n",
    "            # Annotate END\n",
    "            xy = self._get_xy(initial = False)\n",
    "            xytext = xy[0]+0.1,xy[1]-0.05\n",
    "            ax.annotate(\"END\",xy=xy,xytext=xytext,weight = \"bold\")\n",
    "\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        if return_img:\n",
    "            # From https://ndres.me/post/matplotlib-animated-gifs-easily/\n",
    "            fig.canvas.draw_idle()\n",
    "            image = np.frombuffer(fig.canvas.tostring_rgb(), dtype='uint8')\n",
    "            image  = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
    "            plt.close()\n",
    "            return image\n",
    "        else:\n",
    "            plt.show()\n",
    "            \n",
    "    def reset(self):\n",
    "\n",
    "        # Stops placeholder\n",
    "        self.stops = [0,1]\n",
    "\n",
    "        # Random first stop\n",
    "        first_stop = np.random.randint(self.n_stops)\n",
    "        self.stops.append(first_stop)\n",
    "\n",
    "        return first_stop\n",
    "\n",
    "    def step(self,destination):\n",
    "\n",
    "        # Get current state\n",
    "        state = self._get_state()\n",
    "        new_state = destination\n",
    "\n",
    "        # Get reward for such a move\n",
    "        reward = self._get_reward(state,new_state)\n",
    "\n",
    "        # Append new_state to stops\n",
    "        self.stops.append(destination)\n",
    "        done = len(self.stops) == self.n_stops\n",
    "\n",
    "        return new_state,reward,done\n",
    "    \n",
    "\n",
    "    def _get_state(self):\n",
    "        return self.stops[-1]\n",
    "\n",
    "\n",
    "    def _get_xy(self,initial = False):\n",
    "        state = self.stops[0] if initial else self._get_state()\n",
    "        x = self.x[state]\n",
    "        y = self.y[state]\n",
    "        return x,y\n",
    "    \n",
    "    def _get_reward(self,state,new_state):\n",
    "        base_reward = self.q_stops[state,new_state]\n",
    "\n",
    "        if self.method == \"angle_diff\":\n",
    "            return base_reward\n",
    "\n",
    "\n",
    "def run_episode(env,agent,verbose = 1):\n",
    "\n",
    "    s = env.reset()\n",
    "    agent.reset_memory()\n",
    "\n",
    "    max_step = env.n_stops\n",
    "    \n",
    "    episode_reward = 0\n",
    "    \n",
    "    i = 0\n",
    "    while i < max_step:\n",
    "\n",
    "        # Remember the states\n",
    "        agent.remember_state(s)\n",
    "\n",
    "        # Choose an action\n",
    "        a = agent.act(s)\n",
    "        \n",
    "        # Take the action, and get the reward from environment\n",
    "        s_next,r,done = env.step(a)\n",
    "\n",
    "        # Tweak the reward\n",
    "        r = -1 * r\n",
    "        \n",
    "        if verbose: print(s_next,r,done)\n",
    "        \n",
    "        # Update our knowledge in the Q-table\n",
    "        agent.train(s,a,r,s_next)\n",
    "        \n",
    "        # Update the caches\n",
    "        episode_reward += r\n",
    "        s = s_next\n",
    "        \n",
    "        # If the episode is terminated\n",
    "        i += 1\n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "    return env,agent,episode_reward\n",
    "\n",
    "class DeliveryQAgent(QAgent):\n",
    "\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "        self.reset_memory()\n",
    "\n",
    "    def act(self,s):\n",
    "\n",
    "        # Get Q Vector\n",
    "        q = np.copy(self.Q[s,:])\n",
    "\n",
    "        # Avoid already visited states\n",
    "        q[self.states_memory] = -np.inf\n",
    "\n",
    "        if np.random.rand() > self.epsilon:\n",
    "            a = np.argmax(q)\n",
    "        else:\n",
    "            a = np.random.choice([x for x in range(self.actions_size) if x not in self.states_memory])\n",
    "\n",
    "        return a\n",
    "\n",
    "\n",
    "    def remember_state(self,s):\n",
    "        self.states_memory.append(s)\n",
    "\n",
    "    def reset_memory(self):\n",
    "        self.states_memory = []\n",
    "\n",
    "\n",
    "\n",
    "def run_n_episodes(env,agent,name=\"training.gif\",n_episodes=1000,render_each=10,fps=10):\n",
    "\n",
    "    # Store the rewards\n",
    "    rewards = []\n",
    "    imgs = []\n",
    "\n",
    "    # Experience replay\n",
    "    for i in tqdm_notebook(range(n_episodes)):\n",
    "\n",
    "        # Run the episode\n",
    "        env,agent,episode_reward = run_episode(env,agent,verbose = 0)\n",
    "        rewards.append(episode_reward)\n",
    "        \n",
    "        if i % render_each == 0:\n",
    "            img = env.render(return_img = True)\n",
    "            imgs.append(img)\n",
    "\n",
    "    # Show rewards\n",
    "    plt.figure(figsize = (15,3))\n",
    "    plt.title(\"Rewards over training\")\n",
    "    plt.plot(rewards)\n",
    "    plt.show()\n",
    "\n",
    "    # Save imgs as gif\n",
    "    imageio.mimsave(name,imgs,fps = fps)\n",
    "\n",
    "    return env,agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38ecdbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base Data Science snippet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89e827a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized environment with 10 incident points\n",
      "Target metric for optimization is angle_diff\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Environment' object has no attribute 'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16736/671093593.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_stops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16736/1659282628.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, n_stops, max_box, method, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# Generate stops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslope_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslope_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generate_stops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Environment' object has no attribute 'x'"
     ]
    }
   ],
   "source": [
    "env = Environment(n_stops = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056e5c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
